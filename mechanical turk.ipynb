{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Model Building Using Text Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HITID</th>\n",
       "      <th>index</th>\n",
       "      <th>body</th>\n",
       "      <th>company</th>\n",
       "      <th>date</th>\n",
       "      <th>score</th>\n",
       "      <th>Worker1</th>\n",
       "      <th>Answer1</th>\n",
       "      <th>Avg</th>\n",
       "      <th>Date</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3L21G7IH4773YI2L6RV6T5G4RTC1YW</td>\n",
       "      <td>1199</td>\n",
       "      <td>I shall do that! I was thinking \"I've had this...</td>\n",
       "      <td>Fitbit</td>\n",
       "      <td>1449270750</td>\n",
       "      <td>3</td>\n",
       "      <td>A2R0YYUAWNT7UD</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-12-05 06:58:53 UTC</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3I7KR83SNAOQ3IGZ6P98Z3JCRQR9KI</td>\n",
       "      <td>1178</td>\n",
       "      <td>Love it. Has helped keep me on track for weigh...</td>\n",
       "      <td>Fitbit</td>\n",
       "      <td>1449265917</td>\n",
       "      <td>2</td>\n",
       "      <td>A1NM7ZPZ3NH412</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-12-05 06:59:05 UTC</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3P7RGTLO6EO481Q4YVN8VYUWX89KA8</td>\n",
       "      <td>1174</td>\n",
       "      <td>I love it because I do not have to stop and pu...</td>\n",
       "      <td>Fitbit</td>\n",
       "      <td>1449251995</td>\n",
       "      <td>2</td>\n",
       "      <td>A3ITZNJQUTIZ4C</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-12-05 07:02:17 UTC</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>373L46LKP7HF9UT8S10LOXXFNV3KJO</td>\n",
       "      <td>409</td>\n",
       "      <td>I never wore a watch, now I wear an Apple Watc...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>1449290608</td>\n",
       "      <td>1</td>\n",
       "      <td>A2R0YYUAWNT7UD</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-12-05 06:59:32 UTC</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3G9UA71JVV5REFMO97BCKSSTHB2J7G</td>\n",
       "      <td>1465</td>\n",
       "      <td>The fallout soundtracks are great, but IMO the...</td>\n",
       "      <td>Spotify</td>\n",
       "      <td>1449249457</td>\n",
       "      <td>1</td>\n",
       "      <td>A1FP3SH704X01V</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-12-05 06:59:41 UTC</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            HITID  index                                               body  company        date  score         Worker1  Answer1  Avg                     Date positive\n",
       "0  3L21G7IH4773YI2L6RV6T5G4RTC1YW   1199  I shall do that! I was thinking \"I've had this...   Fitbit  1449270750      3  A2R0YYUAWNT7UD        2    2  2015-12-05 06:58:53 UTC     True\n",
       "1  3I7KR83SNAOQ3IGZ6P98Z3JCRQR9KI   1178  Love it. Has helped keep me on track for weigh...   Fitbit  1449265917      2  A1NM7ZPZ3NH412        2    2  2015-12-05 06:59:05 UTC     True\n",
       "2  3P7RGTLO6EO481Q4YVN8VYUWX89KA8   1174  I love it because I do not have to stop and pu...   Fitbit  1449251995      2  A3ITZNJQUTIZ4C        2    2  2015-12-05 07:02:17 UTC     True\n",
       "3  373L46LKP7HF9UT8S10LOXXFNV3KJO    409  I never wore a watch, now I wear an Apple Watc...    Apple  1449290608      1  A2R0YYUAWNT7UD        2    2  2015-12-05 06:59:32 UTC     True\n",
       "4  3G9UA71JVV5REFMO97BCKSSTHB2J7G   1465  The fallout soundtracks are great, but IMO the...  Spotify  1449249457      1  A1FP3SH704X01V        2    2  2015-12-05 06:59:41 UTC     True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "critics = pd.read_csv('comments1_with_sentiments.csv')\n",
    "#let's drop rows with missing quotes\n",
    "critics['positive'] = critics['Answer1'] >= 0\n",
    "critics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grp = critics.groupby('company')\n",
    "avg = grp.Answer1.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "company\n",
       "Airbnb        -3\n",
       "Amazon       -12\n",
       "Apple        -39\n",
       "Asana          0\n",
       "Buzzfeed       1\n",
       "Coursera      -1\n",
       "DoorDash       0\n",
       "Dropbox        2\n",
       "Fitbit        -8\n",
       "Google       -10\n",
       "Hubspot        0\n",
       "Instagram     18\n",
       "Jawbone       -1\n",
       "Kayak          0\n",
       "Laserfiche    -1\n",
       "LinkedIn      -1\n",
       "Lyft         -25\n",
       "Microsoft     -2\n",
       "Pinterest      1\n",
       "Quora          0\n",
       "Riot_Games    -3\n",
       "Snapchat      11\n",
       "Spotify        1\n",
       "Tinder       -20\n",
       "Twitter        1\n",
       "Uber           5\n",
       "Vivint         0\n",
       "YikYak         0\n",
       "Name: Answer1, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Make X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_xy(critics, vectorizer=None):\n",
    "    #Your code here    \n",
    "    if vectorizer is None:\n",
    "        vectorizer = CountVectorizer(encoding = 'utf-8', strip_accents = 'ascii', stop_words='english')\n",
    "    X = vectorizer.fit_transform(critics.body)\n",
    "    X = X.tocsc()  # some versions of sklearn return COO format\n",
    "    y = (critics.Answer1).values.astype(np.int)\n",
    "    return X, y\n",
    "def make_xyBinary(critics, vectorizer=None):\n",
    "    #Your code here    \n",
    "    if vectorizer is None:\n",
    "        vectorizer = CountVectorizer(encoding = 'utf-8', strip_accents = 'ascii', stop_words='english')\n",
    "    X = vectorizer.fit_transform(critics.body)\n",
    "    X = X.tocsc()  # some versions of sklearn return COO format\n",
    "    y = (critics.positive).values.astype(np.int)\n",
    "    return X, y\n",
    "X, y = make_xy(critics)\n",
    "Xbin, ybin = make_xyBinary(critics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<1846x5952 sparse matrix of type '<type 'numpy.int64'>'\n",
       " \twith 22897 stored elements in Compressed Sparse Column format>,\n",
       " array([ 2,  2,  2, ..., -1, -1, -1]))"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_xy(critics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MN Accuracy: 54.98%\n",
      "RF Accuracy: 56.28%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X, y)\n",
    "clf = MultinomialNB().fit(xtrain, ytrain)\n",
    "print \"MN Accuracy: %0.2f%%\" % (100 * clf.score(xtest, ytest))\n",
    "\n",
    "another = RandomForestClassifier(n_estimators=100, min_samples_split=2, n_jobs=-1).fit(xtrain,ytrain)\n",
    "print \"RF Accuracy: %.02f%%\" % (100*another.score(xtest,ytest))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Accuracy: 58.23%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic = LogisticRegression(penalty=\"l1\").fit(xtrain, ytrain)\n",
    "print \"Logistic Accuracy: %.02f%%\" % (100*logistic.score(xtest,ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 0.88\n",
      "Accuracy on test data:     0.55\n",
      "Accuracy on training data: 1.00\n",
      "Accuracy on test 0.56\n",
      "Accuracy on training data: 0.81\n",
      "Accuracy on test 0.58\n"
     ]
    }
   ],
   "source": [
    "training_accuracy = clf.score(xtrain, ytrain)\n",
    "test_accuracy = clf.score(xtest, ytest)\n",
    "\n",
    "rf_train_accuracy = another.score(xtrain, ytrain)\n",
    "rf_test_accuracy = another.score(xtest, ytest)\n",
    "\n",
    "lr_train_accuracy = logistic.score(xtrain,ytrain)\n",
    "lr_test_accuracy = logistic.score(xtest,ytest)\n",
    "\n",
    "print \"Accuracy on training data: %0.2f\" % (training_accuracy)\n",
    "print \"Accuracy on test data:     %0.2f\" % (test_accuracy)\n",
    "\n",
    "print \"Accuracy on training data: %0.2f\" % (rf_train_accuracy)\n",
    "print \"Accuracy on test %0.2f\" % (rf_test_accuracy)\n",
    "\n",
    "print \"Accuracy on training data: %0.2f\" % (lr_train_accuracy)\n",
    "print \"Accuracy on test %0.2f\" % (lr_test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "def cv_score(clf, X, y, scorefunc):\n",
    "    result = 0.\n",
    "    nfold = 5\n",
    "    for train, test in KFold(y.size, nfold): # split data into train/test groups, 5 times\n",
    "        clf.fit(X[train], y[train]) # fit\n",
    "        result += scorefunc(clf, X[test], y[test]) # evaluate score function on held-out data\n",
    "    return result / nfold # average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_likelihood(clf, x, y):\n",
    "    prob = clf.predict_log_proba(x)\n",
    "    rotten = y < 0\n",
    "    fresh = ~rotten\n",
    "    return prob[rotten, 0].sum() + prob[fresh, 1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "itrain, itest = train_test_split(xrange(critics.shape[0]), train_size=0.7)\n",
    "mask=np.ones(critics.shape[0], dtype='int')\n",
    "mask[itrain]=1\n",
    "mask[itest]=0\n",
    "mask = (mask==1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alphas = [0, .1, 1, 5, 10, 50]\n",
    "min_dfs = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1]\n",
    "\n",
    "#Find the best value for alpha and min_df, and the best classifier\n",
    "best_alpha = None\n",
    "best_min_df = None\n",
    "maxscore=-np.inf\n",
    "for alpha in alphas:\n",
    "    for min_df in min_dfs:         \n",
    "        vectorizer = CountVectorizer(min_df = min_df)       \n",
    "        Xthis, ythis = make_xy(critics, vectorizer)\n",
    "        Xtrainthis=Xthis[mask]\n",
    "        ytrainthis=ythis[mask]\n",
    "        #your code here\n",
    "        clf = MultinomialNB(alpha=alpha)\n",
    "        cvscore = cv_score(clf, Xtrainthis, ytrainthis, log_likelihood)\n",
    "\n",
    "        if cvscore > maxscore:\n",
    "            maxscore = cvscore\n",
    "            best_alpha, best_min_df = alpha, min_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 0.62\n",
      "Accuracy on test data:     0.59\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(min_df=best_min_df)\n",
    "X, y = make_xy(critics, vectorizer)\n",
    "xtrain=X[mask]\n",
    "ytrain=y[mask]\n",
    "xtest=X[~mask]\n",
    "ytest=y[~mask]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "clf = MultinomialNB(alpha=best_alpha).fit(xtrain, ytrain)\n",
    "\n",
    "# Your code here. Print the accuracy on the test and training dataset\n",
    "training_accuracy = clf.score(xtrain, ytrain)\n",
    "test_accuracy = clf.score(xtest, ytest)\n",
    "\n",
    "\n",
    "\n",
    "print \"Accuracy on training data: %0.2f\" % (training_accuracy)\n",
    "print \"Accuracy on test data:     %0.2f\" % (test_accuracy)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_ests = [10, 20, 50, 100, 150, 200]\n",
    "min_dfs = [0,.1,.01,.001,.0001,1]\n",
    "max_depths = [5,10,15,20,25,40,50,70,80,90]\n",
    "\n",
    "#Find the best value for alpha and min_df, and the best classifier\n",
    "best_n_est = 10\n",
    "maxscore=-np.inf\n",
    "for max_depth in max_depths:\n",
    "    for n_est in n_ests:  \n",
    "        for min_df in min_dfs:\n",
    "            vectorizer = CountVectorizer(min_df = min_df)       \n",
    "            Xthis, ythis = make_xy(critics, vectorizer)\n",
    "            Xtrainthis=Xthis[mask]\n",
    "            ytrainthis=ythis[mask]\n",
    "            #your code here\n",
    "            rf = RandomForestClassifier(n_estimators=n_est,max_depth = max_depth, min_samples_split=2, n_jobs=-1)\n",
    "            cvscore = cv_score(rf, Xtrainthis, ytrainthis, log_likelihood)\n",
    "\n",
    "            if cvscore > maxscore:\n",
    "                maxscore = cvscore\n",
    "                best_n_est, best_min_df, best_max_depth = n_est, min_df, max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_est = range(best_n_est-5, best_n_est+5)\n",
    "min_dfs = range(int(best_min_df), int(best_min_df+5.))\n",
    "max_depths = range(max_depth-5, max_depth+5)\n",
    "\n",
    "best_n_est = n_est[0]\n",
    "maxscore=-np.inf\n",
    "for max_depth in max_depths:\n",
    "    for n_est in n_ests:  \n",
    "        for min_df in min_dfs:\n",
    "            vectorizer = CountVectorizer(min_df = min_df)       \n",
    "            Xthis, ythis = make_xy(critics, vectorizer)\n",
    "            Xtrainthis=Xthis[mask]\n",
    "            ytrainthis=ythis[mask]\n",
    "            #your code here\n",
    "            rf = RandomForestClassifier(n_estimators=n_est,max_depth = max_depth, min_samples_split=2, n_jobs=-1)\n",
    "            cvscore = cv_score(rf, Xtrainthis, ytrainthis, log_likelihood)\n",
    "\n",
    "            if cvscore > maxscore:\n",
    "                maxscore = cvscore\n",
    "                best_n_est, best_min_df, best_max_depth = n_est, min_df, max_depth\n",
    "                \n",
    "print best_n_est, best_min_df, best_max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 0.97\n",
      "Accuracy on test 0.58\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(min_df=best_min_df)\n",
    "X, y = make_xy(critics, vectorizer)\n",
    "xtrain=X[mask]\n",
    "ytrain=y[mask]\n",
    "xtest=X[~mask]\n",
    "ytest=y[~mask]\n",
    "\n",
    "best_rf = RandomForestClassifier(n_estimators=best_n_est, min_samples_split=2, n_jobs=-1).fit(xtrain,ytrain)\n",
    "rf_train_accuracy = best_rf.score(xtrain, ytrain)\n",
    "rf_test_accuracy = best_rf.score(xtest, ytest)\n",
    "\n",
    "print \"Accuracy on training data: %0.2f\" % (rf_train_accuracy)\n",
    "print \"Accuracy on test %0.2f\" % (rf_test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#Random NLTK Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reddit = []\n",
    "for row in range(len(critics.body)):\n",
    "    words = critics.iloc[row].body.split()\n",
    "    temp = (words, critics.iloc[row].Answer1)\n",
    "    reddit.append(temp)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "def get_words_in_tweets(tweets):\n",
    "    all_words = []\n",
    "    for (words, sentiment) in tweets:\n",
    "        all_words.extend(words)\n",
    "    return all_words\n",
    "def get_word_features(wordlist):\n",
    "    wordlist = nltk.FreqDist(wordlist)\n",
    "    word_features = wordlist.keys()\n",
    "    return word_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_features = get_word_features(get_words_in_tweets(reddit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def extract_features(document):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains(%s)' % word] = (word in document_words)\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_set = nltk.classify.apply_features(extract_features, reddit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(training_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.probability import ELEProbDist, FreqDist\n",
    "from nltk import NaiveBayesClassifier\n",
    "from collections import defaultdict\n",
    "def train(labeled_featuresets, estimator=ELEProbDist):\n",
    "    label_probdist = estimator(label_freqdist)\n",
    "    feature_probdist = {}\n",
    "    return NaiveBayesClassifier(label_probdist, feature_probdist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "tweet = 'customer help'\n",
    "print classifier.classify(extract_features(tweet.split()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_bow(text):\n",
    "    words = text.split()\n",
    "    bow = {}\n",
    "    for word in words:\n",
    "        bow[word.lower()] = True\n",
    "    return bow\n",
    "\n",
    "\n",
    "def get_labeled_features(samples):\n",
    "    word_freqs = {}\n",
    "    for tokens, label in reddit:\n",
    "        for token in tokens:\n",
    "            if token not in word_freqs:\n",
    "                word_freqs[token] = {'pos': 0, 'neg': 0}\n",
    "            word_freqs[token][label] += 1\n",
    "    return word_freqs\n",
    "\n",
    "\n",
    "def get_label_probdist(labeled_features):\n",
    "    label_fd = FreqDist()\n",
    "    for item,counts in labeled_features.items():\n",
    "        for label in ['neg','pos']:\n",
    "            if counts[label] > 0:\n",
    "                label_fd.inc(label)\n",
    "    label_probdist = ELEProbDist(label_fd)\n",
    "    return label_probdist\n",
    "\n",
    "\n",
    "def get_feature_probdist(labeled_features):\n",
    "    feature_freqdist = defaultdict(FreqDist)\n",
    "    feature_values = defaultdict(set)\n",
    "    num_samples = len(train_samples) / 2\n",
    "    for token, counts in labeled_features.items():\n",
    "        for label in ['neg','pos']:\n",
    "            feature_freqdist[label, token].inc(True, count=counts[label])\n",
    "            feature_freqdist[label, token].inc(None, num_samples - counts[label])\n",
    "            feature_values[token].add(None)\n",
    "            feature_values[token].add(True)\n",
    "    for item in feature_freqdist.items():\n",
    "        print item[0],item[1]\n",
    "    feature_probdist = {}\n",
    "    for ((label, fname), freqdist) in feature_freqdist.items():\n",
    "        probdist = ELEProbDist(freqdist, bins=len(feature_values[fname]))\n",
    "        feature_probdist[label,fname] = probdist\n",
    "    return feature_probdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-207-e20cccfecf3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlabeled_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_labeled_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreddit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlabel_probdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_label_probdist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabeled_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfeature_probdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_feature_probdist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabeled_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-206-4a5058786062>\u001b[0m in \u001b[0;36mget_labeled_features\u001b[0;34m(samples)\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_freqs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0mword_freqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'pos'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'neg'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mword_freqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mword_freqs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 2"
     ]
    }
   ],
   "source": [
    "labeled_features = get_labeled_features(reddit)\n",
    "\n",
    "label_probdist = get_label_probdist(labeled_features)\n",
    "\n",
    "feature_probdist = get_feature_probdist(labeled_features)\n",
    "\n",
    "classifier = NaiveBayesClassifier(label_probdist, feature_probdist)\n",
    "\n",
    "for sample in test_samples:\n",
    "    print \"%s | %s\" % (sample, classifier.classify(gen_bow(sample)))\n",
    "\n",
    "classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
